{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlSD1GP4v3vpcyJIxsJgSU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nackjaylor/sydney-innovation-program/blob/main/sip_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning (Semantic Segmentation)"
      ],
      "metadata": {
        "id": "-APQg8c0ZXwD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fniNPbmZUW9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us load a pre-trained model of DeepLabV3 with a ResNet50 backbone.\n",
        "\n",
        "The ResNet50 backbone has been pretrained on a dataset called ImageNet which is huge. In this way, the network has seen lots of data, and learnt lots of features."
      ],
      "metadata": {
        "id": "l_kmoOmHcvcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "model = models.segmentation.deeplabv3_resnet50(pretained=True, progress = True)\n",
        "model.classifier = models.segmentation.deeplabv3.DeepLabHead(2048, 1)\n"
      ],
      "metadata": {
        "id": "ttgZkvQrdCjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((64,64))        \n",
        "])\n",
        "\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.PILToTensor(),\n",
        "    lambda x: torch.div(x.type(torch.FloatTensor), 2, rounding_mode='trunc'),\n",
        "    transforms.Resize((64,64))\n",
        "            \n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = datasets.OxfordIIITPet(root='./data/OxfordIITPET', download=True, target_types = \"segmentation\", transform=img_transform, target_transform=mask_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "# train_dataloader = train_dataset\n",
        "test_dataset = datasets.OxfordIIITPet(root='./data/OxfordIITPET', download=True, split=\"test\", target_types = \"segmentation\", transform=img_transform, target_transform=mask_transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "# test_dataloader = test_dataset"
      ],
      "metadata": {
        "id": "Qv0VXrM5e8XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us look at the segmentation masks!"
      ],
      "metadata": {
        "id": "EerWxD9Y-SGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0].squeeze()\n",
        "plt.figure()\n",
        "f, axarr = plt.subplots(2,1)\n",
        "axarr[0].imshow(img.T)\n",
        "axarr[1].imshow(label.T,vmin=0, vmax=1)\n",
        "plt.show()\n",
        "\n",
        "print(label.max())"
      ],
      "metadata": {
        "id": "4e0YYhYehHr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And how does our model work out of the box?"
      ],
      "metadata": {
        "id": "4nbJQf0o-WUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "segment_predict = model(train_features)\n",
        "\n",
        "plt.imshow(segment_predict['out'][0].squeeze().T.detach())\n"
      ],
      "metadata": {
        "id": "PlyqbD05uPsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not very well... Why is this?\n",
        "\n",
        "Well, a part of the network is still randomly initialised. The segmentation head in particular.\n",
        "\n",
        "We need to train the network on our data so it sees what we want it to do and it can make some meaningful decisions."
      ],
      "metadata": {
        "id": "tY0yN0PB-ajD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.MSELoss(reduction='mean')\n",
        "# Specify the optimizer with a lower learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "U11_h_bElvtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "E9aZswWVm3y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_avg = []\n",
        "\n",
        "model.train()\n",
        "model.to(device)\n",
        "print('Training ...')\n",
        "for epoch in range(epochs):\n",
        "    train_loss_avg.append(0)\n",
        "    num_batches = 0\n",
        "    \n",
        "    for image_batch, mask_batch in train_dataloader:\n",
        "        \n",
        "        image_batch = image_batch.to(device)\n",
        "        \n",
        "        segment_predict = model(image_batch)\n",
        "        \n",
        "        # reconstruction error\n",
        "        loss = criterion(segment_predict['out'], mask_batch.to(device))\n",
        "        \n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        \n",
        "        # one step of the optmizer (using the gradients from backpropagation)\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss_avg[-1] += loss.item()\n",
        "        num_batches += 1\n",
        "        \n",
        "    train_loss_avg[-1] /= num_batches\n",
        "    print('Epoch [%d / %d] average error: %f' % (epoch+1, epochs, train_loss_avg[-1]))"
      ],
      "metadata": {
        "id": "0pR2uzSVmiOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"./segnet\")"
      ],
      "metadata": {
        "id": "msTANqNwwWBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "\n",
        "Now let us see how the trained model has performed!\n",
        "\n"
      ],
      "metadata": {
        "id": "ffXAa0on-7CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = next(iter(test_dataloader))\n",
        "\n",
        "# print(f\"Feature batch shape: {train_features.size()}\")\n",
        "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0].squeeze()\n",
        "plt.figure()\n",
        "f, axarr = plt.subplots(2,1)\n",
        "axarr[0].imshow(img.T)\n",
        "axarr[1].imshow(label.T)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tMWAsjRYwhv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Much better right?\n",
        "\n",
        "You can train it for longer, on larger images and it will perform much better."
      ],
      "metadata": {
        "id": "e74Cgn4P_BST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "\n",
        "segment_predict = model(train_features.to(device))\n",
        "\n",
        "plt.imshow(segment_predict['out'][0].squeeze().T.cpu().detach())"
      ],
      "metadata": {
        "id": "gfDVGFc8waxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your own data!\n",
        "\n",
        "You can go through and upload an image of your pet and see if can be segmented by your network.\n",
        "\n",
        "Try different photos! What do you notice about framing, lighting, image orientation etc. which affect the results?"
      ],
      "metadata": {
        "id": "Gb441rJ4_QW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import cv2\n",
        "uploaded = files.upload()\n",
        "filename = \"<YOUR_PET_PHOTO_HERE>.png\"\n",
        "img = cv2.imread(filename)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "Hv47BnNhyOiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = img_transform(img).unsqueeze(0)"
      ],
      "metadata": {
        "id": "--SaeJll4CzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "segment_predict = model(test_image.to(device))\n",
        "\n",
        "plt.imshow(segment_predict['out'][0].squeeze().T.cpu().detach())"
      ],
      "metadata": {
        "id": "hFnxs0FB5rcR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}